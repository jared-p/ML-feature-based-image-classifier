{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f71e5b5b",
   "metadata": {},
   "source": [
    "# ENGR418 Project Stage 2 Group 31\n",
    "\n",
    "By: Jared Paull (63586572), Liam Ross (75469692)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "61d9aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image, ImageFilter\n",
    "import PIL\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307318e5",
   "metadata": {},
   "source": [
    "## Scraping Image Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "1d2aa4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "image_size = 64\n",
    "filter_value = 4\n",
    "angles = []#0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165]\n",
    "for i in range(90):\n",
    "    angles.append(2*i)\n",
    "\n",
    "x,y = get_image_feature_data_testing(\"../data/training\", image_size, filter_value, angles)\n",
    "xt, yt = get_image_feature_data_testing(\"../data/testing\", image_size, filter_value, angles)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "75daed0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Predicted  Circle  Rectangle  Square\n",
      "Shape Actual                              \n",
      "Circle               23          1       3\n",
      "Rectangle             0         25       2\n",
      "Square                4          4      19\n",
      "Percentage of correct classification from model on training data set: 82.72%\n",
      "\n",
      "Shape Predicted  Circle  Rectangle  Square\n",
      "Shape Actual                              \n",
      "Circle               22          1       4\n",
      "Rectangle             0         19       8\n",
      "Square                1          1      25\n",
      "Percentage of correct classification from model on testing data set: 81.48%\n"
     ]
    }
   ],
   "source": [
    "log_regress = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(26,), random_state=1) #hidden_layer_sizes=(?,)\n",
    "log_regress.fit(x,y);\n",
    "\n",
    "\n",
    "pred =  log_regress.predict(x)\n",
    "predicted = confusion_format(pred)\n",
    "actual = confusion_format(y)\n",
    "print(pd.crosstab(actual, predicted, rownames=[\"Shape Actual\"], colnames=[\"Shape Predicted\"]))\n",
    "print(f\"Percentage of correct classification from model on training data set: {100-error_percentage(pred,y):.2f}%\\n\")\n",
    "\n",
    "pred =  log_regress.predict(xt)\n",
    "predicted = confusion_format(pred)\n",
    "actual = confusion_format(yt)\n",
    "print(pd.crosstab(actual, predicted, rownames=[\"Shape Actual\"], colnames=[\"Shape Predicted\"]))\n",
    "print(f\"Percentage of correct classification from model on testing data set: {100-error_percentage(pred,y):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "filter_value = 6\n",
    "angles = [0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210, 225, 240, 255, 270, 295, 310, 325, 340, 365]\n",
    "\n",
    "x,y = get_image_feature_data_testing(\"../data/training\", image_size, filter_value, angles)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b51c5",
   "metadata": {},
   "source": [
    "### Creating Logistic Regression Model\n",
    "\n",
    "Now that all of the image data is collected, and they have a corresponding label. The data can be fit to a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "700c0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating logistic regression model instance that implements a liblinear solver type\n",
    "# liblinear solver implements a coordinate descent algorithm which works well with high dimension (4096 here)\n",
    "log_regress = linear_model.LogisticRegression(solver = \"liblinear\")\n",
    "# method to fit the logistic regression instance with the data collected in the previous cell\n",
    "log_regress.fit(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e27cc",
   "metadata": {},
   "source": [
    "## Testing the algorithm\n",
    "\n",
    "Now that a model exists, image data and labels are scraped from the testing folder, in the exact same fashion as the data collection from the training data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bd97b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code here is the same as that used to get image data from the training folder.\n",
    "# This section will not be commented on, since the previous section covers all aspects of it.\n",
    "# xt,yt represent image (xt) training data, and label (yt) training data\n",
    "\n",
    "xt, yt = get_image_feature_data(\"../data/testing\", image_size, filter_value, angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc53883",
   "metadata": {},
   "source": [
    "## Prediction and Confusion Matrix\n",
    "\n",
    "The training data is fed into the model and an output is predicted (based on the model). Then the outputs from the model are compared with the correct values to see the model accuracy. First the training data is tested on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "7305e267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Predicted  Circle  Rectangle  Square\n",
      "Shape Actual                              \n",
      "Circle               27          0       0\n",
      "Rectangle             0         27       0\n",
      "Square                0          0      27\n",
      "\n",
      "Percentage of model errors from the testing data: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# feed the training data into the model, pred is an array containing the output labels based on the model\n",
    "pred =  log_regress.predict(x)\n",
    "\n",
    "# These are two formatting questions to make the confusion matrix more appealing. Refer to confusion_format function at the bottom.\n",
    "predicted = confusion_format(pred)\n",
    "actual = confusion_format(y)\n",
    "\n",
    "# prints a confusion matrix, rows are true values, and columns are the model's guessed values.\n",
    "print(pd.crosstab(actual, predicted, rownames=[\"Shape Actual\"], colnames=[\"Shape Predicted\"]))\n",
    "\n",
    "# then the percentage of errors is the number of errors divided by the total number of image samples times 100 for percentage.\n",
    "# The error_percentage function is described below in comment detail.\n",
    "print(f\"\\nPercentage of model errors from the testing data: {error_percentage(pred,y):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c44aadb",
   "metadata": {},
   "source": [
    "Next, the testing data is tested on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d8167e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Predicted  Circle  Rectangle  Square\n",
      "Shape Actual                              \n",
      "Circle               12         10       5\n",
      "Rectangle             5         19       3\n",
      "Square                8          7      12\n",
      "\n",
      "Percentage of model errors from the testing data: 46.91%\n"
     ]
    }
   ],
   "source": [
    "# feed the testing data into the model, pred is an array containing the output labels based on the model\n",
    "pred =  log_regress.predict(xt)\n",
    "\n",
    "# These are two formatting questions to make the confusion matrix more appealing. Refer to confusion_format function at the bottom.\n",
    "predicted = confusion_format(pred)\n",
    "actual = confusion_format(yt)\n",
    "\n",
    "# prints a confusion matrix, rows are true values, and columns are the model's guessed values.\n",
    "print(pd.crosstab(actual, predicted, rownames=[\"Shape Actual\"], colnames=[\"Shape Predicted\"]))\n",
    "\n",
    "# then the percentage of errors is the number of errors divided by the total number of image samples times 100 for percentage.\n",
    "# The error_percentage function is described below in comment detail.\n",
    "print(f\"\\nPercentage of model errors from the testing data: {error_percentage(pred,y):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a44fe1",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33653b",
   "metadata": {},
   "source": [
    "# **Functions**\n",
    "\n",
    "All of these functions **must** be ran before anything else. Each function has its purpose discussed, and are each well commented on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c8deda54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns 2^n/2^n image that is the filtered edge detection version\n",
    "def edge_image(image, image_size, filter_value):\n",
    "    image = image.convert(\"L\")\n",
    "    image = image.filter(ImageFilter.FIND_EDGES)\n",
    "    # choose 2^n + 2 in each dimension\n",
    "    image = image.resize((image_size + 2,image_size + 2))\n",
    "    image = PIL.Image.fromarray(np.array(image)[int(1) : int(image.height -1), int(1) : int(image.width - 1)])\n",
    "\n",
    "    data = np.asarray(image)\n",
    "    data[data <= filter_value] = 0\n",
    "    data[data > 0] = 1\n",
    "    #data = data * 5\n",
    "    image = PIL.Image.fromarray(data)\n",
    "#     for i in range(64):\n",
    "#         for j in range(64):\n",
    "#             print(data[i][j], end = \" \")\n",
    "#         print()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "bf5fc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_count(image):\n",
    "    data = np.array(image)\n",
    "    data = np.hstack(data)\n",
    "    count_list = []\n",
    "    for i in range(image.width):\n",
    "        count = 0\n",
    "        for j in range(image.height):\n",
    "            count = count + data[i + j*image.height]\n",
    "        count_list.append(count)\n",
    "    return count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04d0c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_feature_data(rel_dir, image_size, filter_value, angles):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for pic in os.listdir(rel_dir):\n",
    "        image = PIL.Image.open(f\"{rel_dir}/{pic}\")\n",
    "        image = edge_image(image, image_size, filter_value)\n",
    "\n",
    "        #angles = [0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210, 225, 240, 255, 270, 295, 310, 325, 340, 365] # 24 angles\n",
    "        vec = []\n",
    "\n",
    "        for angle in angles:\n",
    "            img = image.rotate(angle)\n",
    "            count = edge_count(img)\n",
    "            vec.append(count)\n",
    "        vec = np.array(vec)\n",
    "        vec = np.hstack(vec)\n",
    "\n",
    "        # examine the name of the picture file, can find correct label based on first letter of the file name.\n",
    "        # c indicates the picture is a circle\n",
    "        if( str.lower(pic[0]) == \"c\"):\n",
    "            # classify circles as a 0\n",
    "            y.append(0)\n",
    "        # r indicates the picture is a rectangle\n",
    "        elif (str.lower(pic[0]) == \"r\"):\n",
    "            # classify rectangle as a 1\n",
    "            y.append(1)\n",
    "        # only other situation is the image is a square\n",
    "        else:\n",
    "            # classify square as a 2\n",
    "            y.append(2)\n",
    "\n",
    "        x.append(vec) # each image has 1536 features\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30355cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will convert from decimal label to strings.\n",
    "# 0=>Circle, 1=>Rectangle, 2=>Square\n",
    "\n",
    "def confusion_format(labels):\n",
    "    test = []\n",
    "    for i in labels:\n",
    "        if i == 0:\n",
    "            test.append(\"Circle\")\n",
    "        elif i == 1:\n",
    "            test.append(\"Rectangle\")\n",
    "        else:\n",
    "            test.append(\"Square\")\n",
    "    test = np.array(test)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a873cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_percentage(pred, y):\n",
    "    \n",
    "    #print(pred)\n",
    "    #print(y)\n",
    "    # the number of errors is the number of differences between the model's labels and the correct labels\n",
    "    errors = 0\n",
    "    for i in range(pred.size):\n",
    "        # pred is the predicted array labels, while y is the actual\n",
    "        if pred[i] != y[i]:\n",
    "            errors = errors + 1\n",
    "            \n",
    "    # then the percentage of errors is the number of errors divided by the total number of image samples times 100 for percentage.\n",
    "    return errors / pred.size * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bf8b218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = Image.open(\"../data/training/rec_1.png\")\n",
    "# image = edge_image(image, 64, 5)\n",
    "#     for i in range(64):\n",
    "#         for j in range(64):\n",
    "#             print(data[i][j], end = \"\")\n",
    "#         print()\n",
    "def get_len(image):\n",
    "    data = np.array(image)\n",
    "    min_index = image.height\n",
    "    max_index = 0\n",
    "    for i in range(image.height):\n",
    "        for j in range(image.width):\n",
    "            if( data[i][j] == 1):\n",
    "                if (min_index > i):\n",
    "                    min_index = i\n",
    "                if( max_index < i):\n",
    "                    max_index = i\n",
    "    return max_index - min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c27eadfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_feature_data_testing(rel_dir, image_size, filter_value, angles):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for pic in os.listdir(rel_dir):\n",
    "        image = PIL.Image.open(f\"{rel_dir}/{pic}\")\n",
    "        image = edge_image(image, image_size, filter_value)\n",
    "\n",
    "        #angles = [0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210, 225, 240, 255, 270, 295, 310, 325, 340, 365] # 24 angles\n",
    "        vec = []\n",
    "\n",
    "        for angle in angles:\n",
    "            img = image.rotate(angle)\n",
    "            length = get_len(img)\n",
    "            vec.append(length)\n",
    "        vec = np.array(vec)\n",
    "        max_len = np.max(vec) / img.height\n",
    "        min_len = np.min(vec) / img.height\n",
    "        avg_len = np.average(vec) / img.height\n",
    "        med_len = np.median(vec) / img.height\n",
    "        vec = [max_len, min_len, avg_len, med_len]\n",
    "\n",
    "        # examine the name of the picture file, can find correct label based on first letter of the file name.\n",
    "        # c indicates the picture is a circle\n",
    "        if( str.lower(pic[0]) == \"c\"):\n",
    "            # classify circles as a 0\n",
    "            y.append(0)\n",
    "        # r indicates the picture is a rectangle\n",
    "        elif (str.lower(pic[0]) == \"r\"):\n",
    "            # classify rectangle as a 1\n",
    "            y.append(1)\n",
    "        # only other situation is the image is a square\n",
    "        else:\n",
    "            # classify square as a 2\n",
    "            y.append(2)\n",
    "\n",
    "        x.append(vec) # each image has 1536 features\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d4d589cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "[0.625, 0.3125, 0.5060763888888888, 0.53125]\n",
      "0.625 0.3125\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(\"../data/training/squ_4.png\")\n",
    "image = edge_image(image, 64, 5)\n",
    "angles = []\n",
    "for i in range(180):\n",
    "    angles.append(i)\n",
    "print(angles)\n",
    "vec = []\n",
    "for angle in angles:\n",
    "    img = image.rotate(angle)\n",
    "    data = np.array(img)\n",
    "    length = get_len(img)\n",
    "    #print(get_len(img))\n",
    "    vec.append(length)\n",
    "vec = np.array(vec)\n",
    "max_len = np.max(vec) / img.height\n",
    "min_len = np.min(vec) / img.height\n",
    "avg_len = np.average(vec) / img.height\n",
    "med_len = np.median(vec) / img.height\n",
    "vec = [max_len, min_len, avg_len, med_len]\n",
    "print(vec)\n",
    "print(max_len, min_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950370e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
